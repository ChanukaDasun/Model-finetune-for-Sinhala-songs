{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChanukaDasun/Model-finetune-for-Sinhala-songs/blob/main/notebooks/sinhala_songs_finetune.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q unsloth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A11hr2K1K2q-",
        "outputId": "ba115a05-5a4f-4294-f480-7f4b6752fd78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m65.9/65.9 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m375.3/375.3 kB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m506.8/506.8 kB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m423.1/423.1 kB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m289.6/289.6 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m122.9/122.9 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m899.7/899.7 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m170.5/170.5 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m123.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m101.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m180.6/180.6 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m62.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m224.9/224.9 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.9.0+cu126 requires torch==2.9.0, but you have torch 2.9.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5npsuKO1x18e"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/Sinhala Songs Corpus.csv\")"
      ],
      "metadata": {
        "id": "wrfu-9poz67s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "XoK32O5oz-iD",
        "outputId": "c52daa90-31d4-4d6a-f278-d75493172158"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    ID                  Title                                    Singer(s)  \\\n",
              "0  1.0     à¶”à¶¶à¶ºà·’ à¶»à¶¸à·Šâ€à¶º à·ƒà¶³ à¶šà·’à¶»à¶«                                 Nanda Malini   \n",
              "1  2.0          à¶¸à·’à¶ºà·”à¶»à·” à¶šà¶½à·Šà¶´à¶±à·                            Victor Rathnayake   \n",
              "2  3.0      à¶¸à¶§ à¶¸à·”à·…à·” à¶½à·œà·€à¶¸ à¶”à¶¶à¶ºà·’  Rookantha Gunathilake & Chandralekha Perera   \n",
              "3  4.0         à·„à·“à¶±à¶ºà¶šà·’ à¶¸à¶§ à¶†à¶¯à¶»à·š              Kasun Kalhara & Uresha Ravihari   \n",
              "4  5.0  à¶…à¶´à·’ à¶‘à¶šà¶¸ à¶»à·‘à¶±à·™ à¶šà·”à¶»à·”à¶½à·Šà¶½à·                         Wijesundara Weragoda   \n",
              "\n",
              "                    Lyricist              Musician                     Album  \\\n",
              "0           Sunil Ariyaratne     H. M. Jayawardena              à·ƒà¶­à·Šâ€à¶ºà¶ºà·š à¶œà·“à¶­à¶º   \n",
              "1      Premakeerthi de Alwis    Sarath Dassanayake  à·€à·’à¶šà·Šà¶§à¶»à·Š à¶»à¶­à·Šà¶±à·à¶ºà¶š à¶œà·“ à¶¯à·à·„à·à¶±   \n",
              "2       Kularatne Ariyawansa    Rohana Weerasinghe         à¶¸à¶§ à¶¸à·”à·…à·” à¶½à·œà·€à¶¸ à¶”à¶¶à¶ºà·’   \n",
              "3    Upul Shantha Sannasgala     Navarathna Gamage     à¶†à¶¯à¶»à¶«à·“à¶º à·€à·ƒà·Šà·ƒà·à¶±à¶º (Film)   \n",
              "4  Ven. Elle Gunawansa Thero  Wijesundara Weragoda     à¶…à¶´à·’ à¶‘à¶šà¶¸ à¶»à·‘à¶±à·™ à¶šà·”à¶»à·”à¶½à·Šà¶½à·   \n",
              "\n",
              "  Released Year                                             Lyrics  \\\n",
              "0          1984  à¶”à¶¶à¶ºà·’ à¶»à¶¸à·Šâ€à¶º à·ƒà¶³ à¶šà·’à¶»à¶« à¶à¶« à¶…à¶±à·Šà¶°à¶šà·à¶»à·š\\nà¶”à¶¶à¶ºà·’ à·ƒà·à¶¸à·Šà¶º à¶­à¶»à·...   \n",
              "1          1985  à¶¸à·’à¶ºà·”à¶»à·” à¶šà¶½à·Šà¶´à¶±à· à¶±à·™à¶­à¶š à¶¯à·à¶½à·Šà·€à·”à¶«à·\\nà¶…à¶¸à¶ºà·”à¶»à·” à¶»à·ƒ à·„à·ƒà¶šà·à¶±à·Š ...   \n",
              "2          1982  à¶¸à¶§ à¶¸à·”à·…à·” à¶½à·œà·€à¶¸ à¶”à¶¶à¶ºà·’\\nà¶¸à¶œà·š à¶¸à·”à·…à·” à¶½à·œà·€à¶¸ à¶”à¶¶à¶ºà·’\\nà·ƒà·’à¶±à·„à·€ à¶š...   \n",
              "3          2004  à·„à·.. à·„à·.. à·„à·.. à·„à·..\\nà·„à·Šà¶¸à·Š.. à·„à·Šà¶¸à·Š.. à·„à·Šà¶¸à·Š..\\n\\nà·„...   \n",
              "4          2012  à¶…à¶´à·’ à¶‘à¶šà¶¸ à¶»à·‘à¶±à·š à¶šà·”à¶»à·”à¶½à·Šà¶½à·\\nà¶…à¶´à·’ à¶‘à¶šà¶¸ à¶»à·‘à¶±à·š à¶šà·”à¶»à·”à¶½à·Šà¶½à·\\n...   \n",
              "\n",
              "                         Metaphor          Source Domain Target Domain  \\\n",
              "0  à¶”à¶¶à¶ºà·’ à¶»à¶¸à·Šâ€à¶º à·ƒà¶³ à¶šà·’à¶»à¶« à¶à¶« à¶…à¶±à·Šà¶°à¶šà·à¶»à·š                   Moon         Girls   \n",
              "1           à¶¸à·„ à·ƒà¶¸à·”à¶¯à·”à¶» à¶¯à·’à¶º à¶»à·à¶½à·Šà¶½à¶šà·’                  Ocean   Tributaries   \n",
              "2               à¶¸à¶§ à¶¸à·”à·…à·” à¶½à·œà·€à¶¸ à¶”à¶¶à¶ºà·’                  World         Girls   \n",
              "3                  à·„à·“à¶±à¶ºà¶šà·’ à¶¸à¶§ à¶†à¶¯à¶»à·š  Dreams & Imaginations      Emotions   \n",
              "4           à¶…à¶´à·’ à¶‘à¶šà¶¸ à¶»à·‘à¶±à·™ à¶šà·”à¶»à·”à¶½à·Šà¶½à·                Animals        People   \n",
              "\n",
              "                                   Meaning  \n",
              "0                You brightens up my world  \n",
              "1       I can do anything for your comfort  \n",
              "2                   You are my whole world  \n",
              "3                    Love is a dream to me  \n",
              "4  We are unite as birds of the same flock  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-686b2312-c23d-433a-be6b-508f44af15ef\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Title</th>\n",
              "      <th>Singer(s)</th>\n",
              "      <th>Lyricist</th>\n",
              "      <th>Musician</th>\n",
              "      <th>Album</th>\n",
              "      <th>Released Year</th>\n",
              "      <th>Lyrics</th>\n",
              "      <th>Metaphor</th>\n",
              "      <th>Source Domain</th>\n",
              "      <th>Target Domain</th>\n",
              "      <th>Meaning</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>à¶”à¶¶à¶ºà·’ à¶»à¶¸à·Šâ€à¶º à·ƒà¶³ à¶šà·’à¶»à¶«</td>\n",
              "      <td>Nanda Malini</td>\n",
              "      <td>Sunil Ariyaratne</td>\n",
              "      <td>H. M. Jayawardena</td>\n",
              "      <td>à·ƒà¶­à·Šâ€à¶ºà¶ºà·š à¶œà·“à¶­à¶º</td>\n",
              "      <td>1984</td>\n",
              "      <td>à¶”à¶¶à¶ºà·’ à¶»à¶¸à·Šâ€à¶º à·ƒà¶³ à¶šà·’à¶»à¶« à¶à¶« à¶…à¶±à·Šà¶°à¶šà·à¶»à·š\\nà¶”à¶¶à¶ºà·’ à·ƒà·à¶¸à·Šà¶º à¶­à¶»à·...</td>\n",
              "      <td>à¶”à¶¶à¶ºà·’ à¶»à¶¸à·Šâ€à¶º à·ƒà¶³ à¶šà·’à¶»à¶« à¶à¶« à¶…à¶±à·Šà¶°à¶šà·à¶»à·š</td>\n",
              "      <td>Moon</td>\n",
              "      <td>Girls</td>\n",
              "      <td>You brightens up my world</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.0</td>\n",
              "      <td>à¶¸à·’à¶ºà·”à¶»à·” à¶šà¶½à·Šà¶´à¶±à·</td>\n",
              "      <td>Victor Rathnayake</td>\n",
              "      <td>Premakeerthi de Alwis</td>\n",
              "      <td>Sarath Dassanayake</td>\n",
              "      <td>à·€à·’à¶šà·Šà¶§à¶»à·Š à¶»à¶­à·Šà¶±à·à¶ºà¶š à¶œà·“ à¶¯à·à·„à·à¶±</td>\n",
              "      <td>1985</td>\n",
              "      <td>à¶¸à·’à¶ºà·”à¶»à·” à¶šà¶½à·Šà¶´à¶±à· à¶±à·™à¶­à¶š à¶¯à·à¶½à·Šà·€à·”à¶«à·\\nà¶…à¶¸à¶ºà·”à¶»à·” à¶»à·ƒ à·„à·ƒà¶šà·à¶±à·Š ...</td>\n",
              "      <td>à¶¸à·„ à·ƒà¶¸à·”à¶¯à·”à¶» à¶¯à·’à¶º à¶»à·à¶½à·Šà¶½à¶šà·’</td>\n",
              "      <td>Ocean</td>\n",
              "      <td>Tributaries</td>\n",
              "      <td>I can do anything for your comfort</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.0</td>\n",
              "      <td>à¶¸à¶§ à¶¸à·”à·…à·” à¶½à·œà·€à¶¸ à¶”à¶¶à¶ºà·’</td>\n",
              "      <td>Rookantha Gunathilake &amp; Chandralekha Perera</td>\n",
              "      <td>Kularatne Ariyawansa</td>\n",
              "      <td>Rohana Weerasinghe</td>\n",
              "      <td>à¶¸à¶§ à¶¸à·”à·…à·” à¶½à·œà·€à¶¸ à¶”à¶¶à¶ºà·’</td>\n",
              "      <td>1982</td>\n",
              "      <td>à¶¸à¶§ à¶¸à·”à·…à·” à¶½à·œà·€à¶¸ à¶”à¶¶à¶ºà·’\\nà¶¸à¶œà·š à¶¸à·”à·…à·” à¶½à·œà·€à¶¸ à¶”à¶¶à¶ºà·’\\nà·ƒà·’à¶±à·„à·€ à¶š...</td>\n",
              "      <td>à¶¸à¶§ à¶¸à·”à·…à·” à¶½à·œà·€à¶¸ à¶”à¶¶à¶ºà·’</td>\n",
              "      <td>World</td>\n",
              "      <td>Girls</td>\n",
              "      <td>You are my whole world</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.0</td>\n",
              "      <td>à·„à·“à¶±à¶ºà¶šà·’ à¶¸à¶§ à¶†à¶¯à¶»à·š</td>\n",
              "      <td>Kasun Kalhara &amp; Uresha Ravihari</td>\n",
              "      <td>Upul Shantha Sannasgala</td>\n",
              "      <td>Navarathna Gamage</td>\n",
              "      <td>à¶†à¶¯à¶»à¶«à·“à¶º à·€à·ƒà·Šà·ƒà·à¶±à¶º (Film)</td>\n",
              "      <td>2004</td>\n",
              "      <td>à·„à·.. à·„à·.. à·„à·.. à·„à·..\\nà·„à·Šà¶¸à·Š.. à·„à·Šà¶¸à·Š.. à·„à·Šà¶¸à·Š..\\n\\nà·„...</td>\n",
              "      <td>à·„à·“à¶±à¶ºà¶šà·’ à¶¸à¶§ à¶†à¶¯à¶»à·š</td>\n",
              "      <td>Dreams &amp; Imaginations</td>\n",
              "      <td>Emotions</td>\n",
              "      <td>Love is a dream to me</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>à¶…à¶´à·’ à¶‘à¶šà¶¸ à¶»à·‘à¶±à·™ à¶šà·”à¶»à·”à¶½à·Šà¶½à·</td>\n",
              "      <td>Wijesundara Weragoda</td>\n",
              "      <td>Ven. Elle Gunawansa Thero</td>\n",
              "      <td>Wijesundara Weragoda</td>\n",
              "      <td>à¶…à¶´à·’ à¶‘à¶šà¶¸ à¶»à·‘à¶±à·™ à¶šà·”à¶»à·”à¶½à·Šà¶½à·</td>\n",
              "      <td>2012</td>\n",
              "      <td>à¶…à¶´à·’ à¶‘à¶šà¶¸ à¶»à·‘à¶±à·š à¶šà·”à¶»à·”à¶½à·Šà¶½à·\\nà¶…à¶´à·’ à¶‘à¶šà¶¸ à¶»à·‘à¶±à·š à¶šà·”à¶»à·”à¶½à·Šà¶½à·\\n...</td>\n",
              "      <td>à¶…à¶´à·’ à¶‘à¶šà¶¸ à¶»à·‘à¶±à·™ à¶šà·”à¶»à·”à¶½à·Šà¶½à·</td>\n",
              "      <td>Animals</td>\n",
              "      <td>People</td>\n",
              "      <td>We are unite as birds of the same flock</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-686b2312-c23d-433a-be6b-508f44af15ef')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-686b2312-c23d-433a-be6b-508f44af15ef button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-686b2312-c23d-433a-be6b-508f44af15ef');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-503e9e4b-fd23-41bb-855a-2c1ca2f7fa5e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-503e9e4b-fd23-41bb-855a-2c1ca2f7fa5e')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-503e9e4b-fd23-41bb-855a-2c1ca2f7fa5e button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 103,\n  \"fields\": [\n    {\n      \"column\": \"ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8.803408430829505,\n        \"min\": 1.0,\n        \"max\": 30.0,\n        \"num_unique_values\": 30,\n        \"samples\": [\n          28.0,\n          16.0,\n          24.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 98,\n        \"samples\": [\n          \"\\u0daf\\u0dd2\\u0dc0\\u0dca\\u200d\\u0dba\\u0d82\\u0d9c\\u0db1\\u0dcf\\u0dc0\\u0dd3\",\n          \"\\u0db8\\u0daf\\u0dd4 \\u0db8\\u0dbd \\u0dbd\\u0dd9\\u0dc3\",\n          \"\\u0db8\\u0dd2\\u0db1\\u0dd2\\u0dc3\\u0d9a\\u0dd4 \\u0db4\\u0dd2\\u0da7 \\u0db1\\u0dd0\\u0d9c\\u0dd3 \\u0d85\\u0dc3\\u0dbb\\u0dd4\\u0dc0\\u0dd9\\u0d9a\\u0dd2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Singer(s)\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 65,\n        \"samples\": [\n          \"Supun Perera\\r\",\n          \"Ashan Fernando\",\n          \"Nanda Malini\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Lyricist\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 71,\n        \"samples\": [\n          \"Rathna Sri Wijesinghe\",\n          \"Sunil Ariyaratne\",\n          \"Sampath Fernandopulle\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Musician\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 26,\n        \"samples\": [\n          \"Nimesh Kulasinghe\",\n          \"Austin Munasinghe\",\n          \"H. M. Jayawardena\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Album\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 95,\n        \"samples\": [\n          \"\\u0d9c\\u0dbd\\u0db1 \\u0d9c\\u0d9f\",\n          \"\\u0dc3\\u0d82\\u0dc3\\u0dcf\\u0dbb\\u0dda \\u0dc3\\u0dd9\\u0dc0\\u0db1\\u0dd0\\u0dbd\\u0dca\\u0dbd \",\n          \"\\u0dc3\\u0db3\\u0dc0\\u0dad\\u0dd2\\u0dba \\u0d94\\u0db6\\u0dba\\u0dd2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Released Year\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 32,\n        \"samples\": [\n          \"2003\",\n          \"2019\",\n          \"1995\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Lyrics\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 99,\n        \"samples\": [\n          \"\\u0dc3\\u0dd2\\u0dad\\u0dd2\\u0db1\\u0dca \\u0db4\\u0dca\\u200d\\u0dbb\\u0dda\\u0db8 \\u0dc0\\u0da9\\u0db1\\u0dcf\\r\\n\\u0db8\\u0dcf \\u0dc3\\u0dd4\\u0dbb\\u0d82\\u0d9c\\u0db1\\u0dcf\\u0dc0\\u0dd3\\r\\n\\u0db8\\u0d9c\\u0dda \\u0dbd\\u0dba\\u0dda \\u0daf\\u0dd0\\u0dc0\\u0da7\\u0dd3\\r\\n\\u0daf\\u0dd4\\u0d9a\\u0dca \\u0dad\\u0dd0\\u0dc0\\u0dd4\\u0dbd\\u0dca \\u0db1\\u0dd2\\u0dc0\\u0dcf\\u0dc0\\u0dd3\\r\\n\\u0dad\\u0dcf\\u0dbb\\u0d9a\\u0dcf \\u0dbb\\u0dd2\\u0daf\\u0dd3 \\u0dc3\\u0dd2\\u0db1\\u0dcf\\u0dc0\\u0db1\\u0dca\\r\\n\\u0d85\\u0dc4\\u0dc3\\u0dca\\u0d9a\\u0dd4\\u0dc3 \\u0db8\\u0dd0\\u0dc0\\u0dd6 \\u0dbb\\u0da7\\u0dcf\\u0dc0\\u0db1\\u0dca\\r\\n\\u0db4\\u0dd3\\u0daf\\u0dd9\\u0db1\\u0dcf \\u0db8\\u0d9c\\u0dda \\u0dc4\\u0dd0\\u0d9c\\u0dd4\\u0db8\\u0dca \\u0dc3\\u0dd2\\u0dad\\u0dca\\u0dad\\u0db8\\u0dca\\r\\n\\u0db8\\u0dcf \\u0daf\\u0dd2\\u0dc0\\u0dca\\u200d\\u0dba\\u0dba \\u0d85\\u0d82\\u0d9c\\u0db1\\u0dcf\\u0dc0\\u0dd3\\r\\n\\r\\n\\u0daf\\u0dda\\u0daf\\u0dd4\\u0db1\\u0dca\\u0db1\\u0dda \\u0dc4\\u0dd3\\u0db1 \\u0d9a\\u0dd0\\u0db1\\u0dca\\u0daf\\u0dd6\\r\\n\\u0db1\\u0dd3\\u0dbd \\u0dc0\\u0dbb\\u0dca\\u0dab\\u0dda\\r\\n\\u0db1\\u0dda\\u0dad\\u0dca\\u200d\\u0dbb\\u0dcf \\u0db8\\u0db1\\u0dbb\\u0db8\\u0dca\\r\\n\\u0dbb\\u0dd1 \\u0d9a\\u0dcf\\u0dbd\\u0dda \\u0dc3\\u0dda\\u0daf \\u0dbb\\u0dd0\\u0db1\\u0dca\\u0daf\\u0dd6\\r\\n\\u0d9a\\u0dda\\u0dc2 \\u0dc3\\u0dda\\u0db1\\u0dcf \\u0db8\\u0dc0\\u0db1\\u0dcf \\u0dc3\\u0dd2\\u0dad\\u0dd4\\u0dc0\\u0db8\\u0dca\\r\\n\\r\\n\\u0dc3\\u0dd2\\u0dad\\u0dd2\\u0db1\\u0dca \\u0db4\\u0dca\\u200d\\u0dbb\\u0dda\\u0db8 \\u0dc0\\u0da9\\u0db1\\u0dcf\\r\\n\\u0db8\\u0dcf \\u0dc3\\u0dd4\\u0dbb\\u0d82\\u0d9c\\u0db1\\u0dcf\\u0dc0\\u0dd3\\r\\n\\u0db8\\u0d9c\\u0dda \\u0dbd\\u0dba\\u0dda \\u0daf\\u0dd0\\u0dc0\\u0da7\\u0dd3\\r\\n\\u0daf\\u0dd4\\u0d9a\\u0dca \\u0dad\\u0dd0\\u0dc0\\u0dd4\\u0dbd\\u0dca \\u0db1\\u0dd2\\u0dc0\\u0dcf\\u0dc0\\u0dd3\\r\\n\\u0dad\\u0dcf\\u0dbb\\u0d9a\\u0dcf \\u0dbb\\u0dd2\\u0daf\\u0dd3 \\u0dc3\\u0dd2\\u0db1\\u0dcf\\u0dc0\\u0db1\\u0dca\\r\\n\\u0d85\\u0dc4\\u0dc3\\u0dca\\u0d9a\\u0dd4\\u0dc3 \\u0db8\\u0dd0\\u0dc0\\u0dd6 \\u0dbb\\u0da7\\u0dcf\\u0dc0\\u0db1\\u0dca\\r\\n\\u0db4\\u0dd3\\u0daf\\u0dd9\\u0db1\\u0dcf \\u0db8\\u0d9c\\u0dda \\u0dc4\\u0dd0\\u0d9c\\u0dd4\\u0db8\\u0dca \\u0dc3\\u0dd2\\u0dad\\u0dca\\u0dad\\u0db8\\u0dca\\r\\n\\u0db8\\u0dcf \\u0daf\\u0dd2\\u0dc0\\u0dca\\u200d\\u0dba\\u0dba \\u0d85\\u0d82\\u0d9c\\u0db1\\u0dcf\\u0dc0\\u0dd3\\r\\n\\r\\n\\u0dc4\\u0dd0\\u0db1\\u0dca\\u0daf\\u0dd1\\u0dc0\\u0dda \\u0dc3\\u0dba\\u0dd4\\u0dbb\\u0dd4 \\u0dad\\u0dd3\\u0dbb\\u0dda\\r\\n\\u0d9a\\u0dd3\\u0dc0 \\u0d9c\\u0dd3\\u0dad\\u0dda \\u0db8\\u0dcf\\u0dad\\u0dca\\u200d\\u0dbb\\u0dcf \\u0dc4\\u0dd4\\u0dbb\\u0dad\\u0dbd\\u0dca\\r\\n\\u0db8\\u0dbd\\u0dca \\u0dc0\\u0dcf\\u0d9c\\u0dd9 \\u0d9a\\u0ddd\\u0dbd \\u0db6\\u0dd0\\u0dbd\\u0dca\\u0db8\\r\\n\\u0db4\\u0dd1\\u0dba\\u0dd4 \\u0db8\\u0dd6\\u0db1\\u0dda \\u0db8\\u0dcf\\u0dba\\u0dcf \\u0dc0\\u0dd2\\u0d9a\\u0dd4\\u0db8\\u0db1\\u0dca\\r\\n\\u0db8\\u0dcf\\u0dbd\\u0dad\\u0dd3 \\u0d9a\\u0ddc\\u0db4\\u0dd4\\u0dbd\\u0dca \\u0dc3\\u0dd2\\u0db1\\u0dcf\\u0dc3\\u0dd3\\r\\n\\u0d86\\u0daf\\u0dbb\\u0dda \\u0daf\\u0ddd\\u0dbb \\u0d9c\\u0dbd\\u0dcf\\u0dc0\\u0dd3\\r\\n\\u0dc3\\u0dd4\\u0dc3\\u0dd4\\u0db8\\u0dca \\u0dc0\\u0dd0\\u0dbd\\u0dca \\u0daf\\u0dd1\\u0dc3\\u0dda \\u0db8\\u0dd2\\u0dba\\u0dd0\\u0daf\\u0dd3\\r\\n\\r\\n\\u0dc3\\u0dd2\\u0dad\\u0dd2\\u0db1\\u0dca \\u0db4\\u0dca\\u200d\\u0dbb\\u0dda\\u0db8 \\u0dc0\\u0da9\\u0db1\\u0dcf\\r\\n\\u0db8\\u0dcf \\u0dc3\\u0dd4\\u0dbb\\u0d82\\u0d9c\\u0db1\\u0dcf\\u0dc0\\u0dd3\\r\\n\\u0db8\\u0d9c\\u0dda \\u0dbd\\u0dba\\u0dda \\u0daf\\u0dd0\\u0dc0\\u0da7\\u0dd3\\r\\n\\u0daf\\u0dd4\\u0d9a\\u0dca \\u0dad\\u0dd0\\u0dc0\\u0dd4\\u0dbd\\u0dca \\u0db1\\u0dd2\\u0dc0\\u0dcf\\u0dc0\\u0dd3\\r\\n\\u0dad\\u0dcf\\u0dbb\\u0d9a\\u0dcf \\u0dbb\\u0dd2\\u0daf\\u0dd3 \\u0dc3\\u0dd2\\u0db1\\u0dcf\\u0dc0\\u0db1\\u0dca\\r\\n\\u0d85\\u0dc4\\u0dc3\\u0dca\\u0d9a\\u0dd4\\u0dc3 \\u0db8\\u0dd0\\u0dc0\\u0dd6 \\u0dbb\\u0da7\\u0dcf\\u0dc0\\u0db1\\u0dca\\r\\n\\u0db4\\u0dd3\\u0daf\\u0dd9\\u0db1\\u0dcf \\u0db8\\u0d9c\\u0dda \\u0dc4\\u0dd0\\u0d9c\\u0dd4\\u0db8\\u0dca \\u0dc3\\u0dd2\\u0dad\\u0dca\\u0dad\\u0db8\\u0dca\\r\\n\\u0db8\\u0dcf \\u0daf\\u0dd2\\u0dc0\\u0dca\\u200d\\u0dba\\u0dba \\u0d85\\u0d82\\u0d9c\\u0db1\\u0dcf\\u0dc0\\u0dd3\\r\\n\\r\\n\\u0dc3\\u0dd2\\u0dad\\u0dd2\\u0db1\\u0dca \\u0db4\\u0dca\\u200d\\u0dbb\\u0dda\\u0db8 \\u0dc0\\u0da9\\u0db1\\u0dcf\\r\\n\\u0db8\\u0dcf \\u0dc3\\u0dd4\\u0dbb\\u0d82\\u0d9c\\u0db1\\u0dcf\\u0dc0\\u0dd3\\r\\n\\u0db8\\u0d9c\\u0dda \\u0dbd\\u0dba\\u0dda \\u0daf\\u0dd0\\u0dc0\\u0da7\\u0dd3\\r\\n\\u0daf\\u0dd4\\u0d9a\\u0dca \\u0dad\\u0dd0\\u0dc0\\u0dd4\\u0dbd\\u0dca \\u0db1\\u0dd2\\u0dc0\\u0dcf\\u0dc0\\u0dd3\\r\\n\\u0dad\\u0dcf\\u0dbb\\u0d9a\\u0dcf \\u0dbb\\u0dd2\\u0daf\\u0dd3 \\u0dc3\\u0dd2\\u0db1\\u0dcf\\u0dc0\\u0db1\\u0dca\\r\\n\\u0d85\\u0dc4\\u0dc3\\u0dca\\u0d9a\\u0dd4\\u0dc3 \\u0db8\\u0dd0\\u0dc0\\u0dd6 \\u0dbb\\u0da7\\u0dcf\\u0dc0\\u0db1\\u0dca\\r\\n\\u0db4\\u0dd3\\u0daf\\u0dd9\\u0db1\\u0dcf \\u0db8\\u0d9c\\u0dda \\u0dc4\\u0dd0\\u0d9c\\u0dd4\\u0db8\\u0dca \\u0dc3\\u0dd2\\u0dad\\u0dca\\u0dad\\u0db8\\u0dca\\r\\n\\u0db8\\u0dcf \\u0daf\\u0dd2\\u0dc0\\u0dca\\u200d\\u0dba\\u0dba \\u0d85\\u0d82\\u0d9c\\u0db1\\u0dcf\\u0dc0\\u0dd3\",\n          \"\\u0db8\\u0daf\\u0dd4 \\u0db8\\u0dbd \\u0dbd\\u0dd9\\u0dc3 \\u0db8\\u0dd8\\u0daf\\u0dd4 \\u0db8\\u0dcf\\u0d9c\\u0dda \\u0db4\\u0dca\\u0dbb\\u0dd2\\u0dba\\u0dcf\\u0daf\\u0dbb \\u0db8\\u0dd2\\u0dc4\\u0dd2\\u0dbb\\u0dcf\\u0dc0\\u0dd2\\u0dba \\u0dc0\\u0dd9\\u0dad\\u0da7\\u0dba\\u0dd2\\n\\u0d94\\u0db6 \\u0dc3\\u0dd2\\u0dc4\\u0dd2 \\u0d9a\\u0dbb \\u0d9a\\u0dbb \\u0d94\\u0db6\\u0da7 \\u0dbd\\u0dd2\\u0dba\\u0db1 \\u0d91\\u0d9a \\u0db8\\u0da7 \\u0d87\\u0dad\\u0dd2 \\u0d91\\u0d9a \\u0dc3\\u0dad\\u0dd4\\u0da7\\u0dba\\u0dd2\\n\\u0d85\\u0db4\\u0db8\\u0db1 \\u0dc3\\u0dd2\\u0dad\\u0dd4\\u0dc0\\u0dd2\\u0dbd\\u0dd2 \\u0db6\\u0dd2\\u0dc4\\u0dd2\\u0dc0\\u0dd2 \\u0dad\\u0dd9\\u0dbb\\u0db4\\u0dd2\\u0dbd\\u0dd2 \\u0d91\\u0d9a\\u0dd2\\u0db1\\u0dd9\\u0d9a \\u0db4\\u0dd0\\u0da7\\u0dbd\\u0dd9\\u0db1\\u0dca\\u0db1\\u0dda\\n\\u0d9a\\u0ddc\\u0dc4\\u0ddc\\u0db8 \\u0db4\\u0da7\\u0db1\\u0dca\\u0d9c\\u0dd9\\u0db1 \\u0db8\\u0ddc\\u0db1\\u0dc0 \\u0dbd\\u0dd2\\u0dba\\u0db1\\u0dca\\u0db1\\u0daf \\u0db1\\u0dd0\\u0dad \\u0db8\\u0da7 \\u0dc0\\u0dd0\\u0da7\\u0dc4\\u0dd9\\u0db1\\u0dca\\u0db1\\u0dda\\n\\u0d9a\\u0dd9\\u0da7\\u0dd2\\u0dba\\u0dd9\\u0db1\\u0dca \\u0db4\\u0dc0\\u0dc3\\u0db8\\u0dd2 \\u0db8\\u0d9c\\u0dda \\u0d86\\u0daf\\u0dbb\\u0dd2\\u0dba\\u0dda \\u0d9a\\u0dd3\\u0db8\\u0da7 \\u0d87\\u0dad\\u0dd2 \\u0dc3\\u0dd0\\u0db8\\u0daf\\u0dda\\n\\u0db4\\u0dbb\\u0dd9\\u0dc0\\u0dd2 \\u0dbb\\u0dd0\\u0da2\\u0dd2\\u0db1\\u0dd2\\u0dba\\u0dda \\u0d91\\u0daf\\u0dcf \\u0dc0\\u0d9c\\u0dd9 \\u0d85\\u0daf\\u0dad\\u0dca \\u0d94\\u0db6\\u0da7 \\u0dad\\u0dc0\\u0db8 \\u0db8\\u0db8 \\u0d86\\u0daf\\u0dbb\\u0dd9\\u0dba\\u0dd2\\n\\u0d94\\u0db6\\u0da7 \\u0dad\\u0dc0\\u0db8 \\u0db8\\u0db8 \\u0d86\\u0daf\\u0dbb\\u0dd9\\u0dba\\u0dd2\\n\\u0db8\\u0daf\\u0dd4 \\u0db8\\u0dbd \\u0dbd\\u0dd9\\u0dc3 \\u0db8\\u0dd8\\u0daf\\u0dd4 \\u0db8\\u0dcf\\u0d9c\\u0dda \\u0db4\\u0dca\\u0dbb\\u0dd2\\u0dba\\u0dcf\\u0daf\\u0dbb \\u0db8\\u0dd2\\u0dc4\\u0dd2\\u0dbb\\u0dcf\\u0dc0\\u0dd2\\u0dba \\u0dc0\\u0dd9\\u0dad\\u0da7\\u0dba\\u0dd2\\n\\u0d94\\u0db6 \\u0dc3\\u0dd2\\u0dc4\\u0dd2 \\u0d9a\\u0dbb \\u0d9a\\u0dbb \\u0d94\\u0db6\\u0da7 \\u0dbd\\u0dd2\\u0dba\\u0db1 \\u0d91\\u0d9a \\u0db8\\u0da7 \\u0d87\\u0dad\\u0dd2 \\u0d91\\u0d9a \\u0dc3\\u0dad\\u0dd4\\u0da7\\u0dba\\u0dd2\\n\\u0dc4\\u0dd2\\u0dad \\u0d9c\\u0ddc\\u0dbd\\u0dd4 \\u0dc0\\u0dd9\\u0db1\\u0dc0\\u0dcf \\u0d85\\u0dad \\u0dc0\\u0dd9\\u0dc0\\u0dca\\u0dbd\\u0db1\\u0dc0\\u0dcf \\u0dc4\\u0daf\\u0dc0\\u0dad \\u0d9c\\u0dd0\\u0dc3\\u0dca\\u0dc3\\u0dd9\\u0db1\\u0dc0\\u0dcf\\n\\u0dbd\\u0dd2\\u0db4\\u0dd2\\u0dba\\u0dd9\\u0dc4\\u0dd2 \\u0d9a\\u0ddc\\u0dbd\\u0dba\\u0da7 \\u0db8\\u0dd4\\u0dc4\\u0dd4\\u0db1 \\u0dba\\u0ddc\\u0db8\\u0db1 \\u0d9a\\u0ddc\\u0da7 \\u0db1\\u0dd9\\u0dad\\u0dca \\u0daf\\u0dd9\\u0d9a \\u0db4\\u0dd2\\u0dba\\u0dc0\\u0dd9\\u0db1\\u0dc0\\u0dcf\\n\\u0d9a\\u0dd9\\u0da7\\u0dd2\\u0dba\\u0dd9\\u0db1\\u0dca \\u0db4\\u0dc0\\u0dc3\\u0db8\\u0dd2 \\u0db8\\u0d9c\\u0dd9 \\u0d86\\u0daf\\u0dbb\\u0dd2\\u0dba\\u0dda \\u0d9a\\u0dd3\\u0db8\\u0da7 \\u0d87\\u0dad\\u0dd2 \\u0dc3\\u0dd0\\u0db8\\u0daf\\u0dda\\n\\u0db4\\u0dbb\\u0dd9\\u0dc0\\u0dd2 \\u0dbb\\u0da2\\u0dd2\\u0db1\\u0dd2\\u0dba\\u0dda \\u0d91\\u0daf\\u0dcf \\u0dc0\\u0d9c\\u0dda \\u0d85\\u0daf\\u0dad\\u0dca \\u0d94\\u0db6\\u0da7 \\u0dad\\u0dc0\\u0db8 \\u0db8\\u0db8 \\u0d86\\u0daf\\u0dbb\\u0dd9\\u0dba\\u0dd2\\n\\u0d94\\u0db6\\u0da7 \\u0dad\\u0dc0\\u0db8 \\u0db8\\u0db8 \\u0d86\\u0daf\\u0dbb\\u0dd9\\u0dba\\u0dd2\\n\\u0d94\\u0db6\\u0da7 \\u0dad\\u0dc0\\u0db8 \\u0db8\\u0db8 \\u0d86\\u0daf\\u0dbb\\u0dd9\\u0dba\\u0dd2\\n\\u0d94\\u0db6\\u0da7 \\u0dad\\u0dc0\\u0db8 \\u0db8\\u0db8 \\u0d86\\u0daf\\u0dbb\\u0dd9\\u0dba\\u0dd2\",\n          \"\\u0db8\\u0dd2\\u0db1\\u0dd2\\u0dc3\\u0dcf \\u0dc3\\u0dd4\\u0dc0\\u0db3\\u0dba\\u0dd2 \\u0db8\\u0dbd \\u0dc3\\u0dda \\u0db1\\u0dd4\\u0dc0\\u0dab\\u0dd2\\u0db1\\u0dca \\u0d91\\u0dc5\\u0dd2\\u0dba\\u0dba\\u0dd2 \\u0dc4\\u0dd2\\u0dbb\\u0dd4 \\u0dc3\\u0dda \\u0db4\\u0dbb\\u0dc0\\u0dd3 \\u0dc0\\u0dd0\\u0da7\\u0dd2\\u0dbd\\u0dcf \\u0d92 \\u0dc4\\u0dd2\\u0dbb\\u0dd4 \\u0db8\\u0dbd \\u0db8\\u0dda \\u0daf\\u0dd9\\u0dbb\\u0dab\\u0dda \\u0db4\\u0ddc\\u0dc5\\u0dc0\\u0dda \\u0d8b\\u0dbb\\u0dd4\\u0db8\\u0dda \\u0d9a\\u0dd2\\u0dba\\u0db8\\u0dd2\\u0db1\\u0dca \\u0db6\\u0dd2\\u0dbd\\u0dd2\\u0daf\\u0dd3 \\u0dc0\\u0dd2\\u0dc4\\u0dd2\\u0d9f\\u0dd4\\u0db8\\u0dca \\u0d9c\\u0dd4\\u0dab\\u0daf\\u0db8\\u0dca \\u0daf\\u0dc4\\u0dc3\\u0dd2\\u0db1\\u0dca \\u0db8\\u0dd2\\u0dba\\u0dd9\\u0db1\\u0dcf \\u0dc3\\u0da7\\u0db1\\u0dd2\\u0db1\\u0dca \\u0d85\\u0d9f\\u0dbd\\u0dda \\u0dc4\\u0dd2\\u0db8\\u0dd2\\u0d9a\\u0db8\\u0dca \\u0dc3\\u0ddc\\u0dba\\u0db8\\u0dd2\\u0db1\\u0dca \\u0dbd\\u0ddc\\u0dc0 \\u0db1\\u0dc4\\u0dc0\\u0dcf \\u0dc3\\u0ddd \\u0d9a\\u0db3\\u0dd4\\u0dbd\\u0dd2\\u0db1\\u0dca \\u0dc3\\u0dd0\\u0db1\\u0dc4\\u0dda \\u0da2\\u0dba \\u0db4\\u0dd0\\u0db1\\u0dca \\u0db4\\u0dd4\\u0dbb\\u0db8\\u0dd2\\u0db1\\u0dca \\u0db8\\u0dd2\\u0db1\\u0dd2\\u0dc3\\u0dcf \\u0dc3\\u0dd4\\u0dc0\\u0db3\\u0dba\\u0dd2.... \\u0d8b\\u0dab\\u0dd4 \\u0dbd\\u0dda \\u0dc0\\u0dd2\\u0dc2 \\u0dc0\\u0dd3 \\u0dc3\\u0dd2\\u0dbb\\u0dd4\\u0dbb\\u0dda \\u0d89\\u0dc3\\u0dd4\\u0dbb\\u0db1\\u0dca \\u0d9c\\u0dd0\\u0da7\\u0dd9\\u0db1\\u0dcf \\u0d85\\u0dad\\u0dbb\\u0dda \\u0d9c\\u0dd2\\u0db1\\u0dd2 \\u0db8\\u0dbd\\u0dca \\u0db4\\u0dd2\\u0db4\\u0dd2\\u0dbd\\u0dcf \\u0d85\\u0dc4\\u0dc3\\u0dda \\u0d87\\u0dc0\\u0dd2\\u0dbd\\u0dda \\u0d9c\\u0dd2\\u0db1\\u0dd2 \\u0daf\\u0dd0\\u0dbd\\u0dca \\u0dc3\\u0dba\\u0dd4\\u0dbb\\u0dda \\u0dc3\\u0dcf \\u0db4\\u0dc0\\u0dc3\\u0dd2\\u0db1\\u0dca \\u0d89\\u0d9a\\u0dd2 \\u0db6\\u0dd2\\u0db3\\u0dd2\\u0db1\\u0dcf \\u0dc3\\u0dd4\\u0dc3\\u0dd4\\u0db8\\u0dd9\\u0db1\\u0dca \\u0dba\\u0daf\\u0dd2\\u0dba\\u0db1\\u0dca \\u0dc4\\u0dd9\\u0dbd\\u0db1\\u0dcf \\u0db8\\u0dd2\\u0db1\\u0dd2\\u0dc3\\u0dcf \\u0dc3\\u0dd4\\u0dc0\\u0db3\\u0dba\\u0dd2...\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Metaphor\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 98,\n        \"samples\": [\n          \"\\u0dad\\u0dcf\\u0dbb\\u0d9a\\u0dcf \\u0dbb\\u0dd2\\u0daf\\u0dd3 \\u0dc3\\u0dd2\\u0db1\\u0dcf\\u0dc0\\u0db1\\u0dca\",\n          \"\\u0db8\\u0daf\\u0dd4 \\u0db8\\u0dbd \\u0dbd\\u0dd9\\u0dc3 \\u0db8\\u0dd8\\u0daf\\u0dd4 \",\n          \"\\u0d92 \\u0db6\\u0dbb \\u0d9c\\u0dd9\\u0dba\\u0dd2 \\u0dc0\\u0dc4\\u0dbd\\u0da7 \\u0db6\\u0dbb\\u0d9a\\u0dd2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Source Domain\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 51,\n        \"samples\": [\n          \"Sun\",\n          \"Lips\",\n          \"Second Buddha\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Target Domain\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 49,\n        \"samples\": [\n          \"House\",\n          \"Cost of living\",\n          \"Blood\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Meaning\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 99,\n        \"samples\": [\n          \"You are the starting point or foundation of the my love and that they are very important to the me\",\n          \"leaving loved person by someone\",\n          \"The hot blood poisons and collides with the body like a fire in the sky\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model\n",
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "\n",
        "max_seq_length = 2048\n",
        "dtype = None\n",
        "load_in_4bit = True\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name='unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit',\n",
        "    max_seq_length=max_seq_length,\n",
        "    dtype=dtype,\n",
        "    load_in_4bit=load_in_4bit\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316,
          "referenced_widgets": [
            "45b8560ceee344789afae9581361ffa3",
            "6ebf12f8343542fc992743768da950fd",
            "b1da440e31cc4d16842da903d85b92ce",
            "5c529993fd90428ab8337690c02d333a",
            "759ed4929bbc4ddabc75958ce644a14c",
            "a9d485b003e34230b71f0bf6fc62e691",
            "122a5beabdd347cd851c4ee80377b7f8",
            "c4243f46ef4a40d6890966e0b35c6fdd",
            "2326480f40f94b3198b4610be1c095b9",
            "1cfdd7ff1d7f406a9da0cf3c71622f7b",
            "334f7abf3f414c5dbc358733e9ba5f95",
            "bb4c84a3db614487aac246af7365fd08",
            "73c0e7317f54427095f6d86233229f98",
            "4ab9c1e1d3824109a49449c2aab42f7a",
            "2cea96b4be86437c86991d837cecd5bb",
            "c30b8b0136c54b85bac5e839a2e27812",
            "28916a5e627f4519b734852367751795",
            "67214f8cfad44add903ffbcf1bbcbc19",
            "cd5d46b000b2431b87986e2c64003578",
            "98656ba1f9b7484aaa8f089cf7fe169c",
            "baa70905e8e5495a92d31472757bdb99",
            "48cf2684b54743b3b990b032e830b4b5",
            "7a6ec5ae66114a439c6bf647f7969a29",
            "c265fc5493e0478da7abe8efb6e6aa18",
            "14c9057d29774828a597836549505151",
            "17e37227126c44e3aad48487d99b8285",
            "d848753b4a764f0c930aff61b9c48fed",
            "38ef317486694bde932e9adbd333f777",
            "2074243ffe3a479298d623c502fdbc76",
            "1d7e3078da064e9db2e61f786f4f8b8f",
            "541b1e64e708475fa6dcf99268b524cd",
            "edce2d932cbc41e6ad63e4169940d4d0",
            "7788c401691f4751ac334b2c9faf0654",
            "f15ddda89e974d64ac0ecce5e05be2e3",
            "03d9b1688c2d42b5b16ba88e457e29d2",
            "5fe72fdef2834dc1bb7643869746beb9",
            "2b2d84d82dcd407aabc695431e9b78e6",
            "1730e779e73046a4b8f9128e77f98747",
            "de9745b68b2a43eb948b3d76ebf80815",
            "9fceb43f1724482caa2e07f4b1beece6",
            "4f0efcf4f78e417ca113cf83d1e0b21b",
            "164928eb4e6b43adb6422da29cffac73",
            "42184520d4b54469828f0ab13d51f1c9",
            "6c4b03ebcc034b7789fc2c47fbbff70c",
            "abb02f2bbc6f4b7780fdd1b1f05a150d",
            "939532ca637e44c4bf7e21f75babb370",
            "b1af255e01bc4ba3bde6338e09b16810",
            "dec1b7f2368142c0b73ea588ecd06f6f",
            "8560c15b58f64319a5a31a30bad3875c",
            "70eaceca5cf14590bc0156a3b92d179b",
            "e2ff8c3fed6d4631b930b6cab716de46",
            "2a3f0a2716ad4d7b9e805062dc3a1311",
            "6e39d3152c9948239cbc07e7fd2a6389",
            "b287b6a234d248de95c7a5626eacc359",
            "d31f9c874a404c27a951674c763ea815"
          ]
        },
        "id": "ELHsB2ITKykJ",
        "outputId": "a6dedad7-17b9-4994-acda-3fb9bca6c32e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "ğŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
            "==((====))==  Unsloth 2025.12.7: Fast Llama patching. Transformers: 4.57.3.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.9.1+cu128. CUDA: 7.5. CUDA Toolkit: 12.8. Triton: 3.5.1\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.33.post2. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/5.70G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "45b8560ceee344789afae9581361ffa3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bb4c84a3db614487aac246af7365fd08"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7a6ec5ae66114a439c6bf647f7969a29"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/454 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f15ddda89e974d64ac0ecce5e05be2e3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "abb02f2bbc6f4b7780fdd1b1f05a150d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare dataset for finetuning using augmantation\n",
        "import json\n",
        "import random\n",
        "from typing import List, Dict\n",
        "from datasets import Dataset\n",
        "\n",
        "class SinhalaDatasetForUnsloth:\n",
        "    \"\"\"\n",
        "    Prepares Sinhala songs dataset for Unsloth fine-tuning\n",
        "    Compatible with the text-based format expected by SFTTrainer\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, df: pd.DataFrame, tokenizer=None):\n",
        "        self.df = df\n",
        "        self.tokenizer = tokenizer\n",
        "        self.training_data = []\n",
        "\n",
        "        # Prompt template (customize based on your needs)\n",
        "        self.prompt_template = \"\"\"Below is a question about Sinhala songs. Provide an accurate and helpful answer.\n",
        "        ### Question:\n",
        "        {}\n",
        "\n",
        "        ### Answer:\n",
        "        {}\"\"\"\n",
        "\n",
        "    def create_song_info_examples(self, row: pd.Series) -> List[Dict]:\n",
        "        \"\"\"Generate song information examples\"\"\"\n",
        "        examples = []\n",
        "\n",
        "        # Variation 1: Basic info\n",
        "        question = f\"Tell me about the song '{row['Title']}'\"\n",
        "        answer = (\n",
        "            f\"{row['Title']} is a Sinhala song sung by {row['Singer(s)']}. \"\n",
        "            f\"The lyrics were written by {row['Lyricist']} and the music was composed by {row['Musician']}. \"\n",
        "            f\"It was released in {row['Released Year']} as part of the album '{row['Album']}'.\"\n",
        "        )\n",
        "        examples.append({\"question\": question, \"answer\": answer})\n",
        "\n",
        "        # Variation 2: Sinhala query\n",
        "        question_si = f\"'{row['Title']}' à¶œà·“à¶­à¶º à¶œà·à¶± à¶šà·’à¶ºà¶±à·Šà¶±\"\n",
        "        examples.append({\"question\": question_si, \"answer\": answer})\n",
        "\n",
        "        # Variation 3: What do you know\n",
        "        question = f\"What do you know about {row['Title']}?\"\n",
        "        examples.append({\"question\": question, \"answer\": answer})\n",
        "\n",
        "        return examples\n",
        "\n",
        "    def create_singer_examples(self, row: pd.Series) -> List[Dict]:\n",
        "        \"\"\"Generate singer query examples\"\"\"\n",
        "        examples = []\n",
        "\n",
        "        question = f\"Who sang '{row['Title']}'?\"\n",
        "        answer = f\"'{row['Title']}' was sung by {row['Singer(s)']}.\"\n",
        "        examples.append({\"question\": question, \"answer\": answer})\n",
        "\n",
        "        question_si = f\"'{row['Title']}' à¶œà·“à¶­à¶º à¶œà·à¶ºà¶±à¶º à¶šà·…à·š à¶šà·€à·”à¶¯?\"\n",
        "        examples.append({\"question\": question_si, \"answer\": answer})\n",
        "\n",
        "        return examples\n",
        "\n",
        "    def create_lyricist_examples(self, row: pd.Series) -> List[Dict]:\n",
        "        \"\"\"Generate lyricist query examples\"\"\"\n",
        "        if pd.isna(row['Lyricist']):\n",
        "            return []\n",
        "\n",
        "        examples = []\n",
        "\n",
        "        question = f\"Who wrote the lyrics for '{row['Title']}'?\"\n",
        "        answer = f\"The lyrics of '{row['Title']}' were written by {row['Lyricist']}.\"\n",
        "        examples.append({\"question\": question, \"answer\": answer})\n",
        "\n",
        "        question_si = f\"'{row['Title']}' à¶œà·“à¶­à¶ºà·š à¶œà·“ à¶»à¶ à¶šà¶ºà· à¶šà·€à·”à¶¯?\"\n",
        "        examples.append({\"question\": question_si, \"answer\": answer})\n",
        "\n",
        "        return examples\n",
        "\n",
        "    def create_musician_examples(self, row: pd.Series) -> List[Dict]:\n",
        "        \"\"\"Generate music composer examples\"\"\"\n",
        "        examples = []\n",
        "\n",
        "        question = f\"Who composed the music for '{row['Title']}'?\"\n",
        "        answer = f\"The music for '{row['Title']}' was composed by {row['Musician']}.\"\n",
        "        examples.append({\"question\": question, \"answer\": answer})\n",
        "\n",
        "        question_si = f\"'{row['Title']}' à¶œà·“à¶­à¶ºà·š à·ƒà¶‚à¶œà·“à¶­à¶º à¶»à¶ à¶±à· à¶šà·…à·š à¶šà·€à·”à¶¯?\"\n",
        "        examples.append({\"question\": question_si, \"answer\": answer})\n",
        "\n",
        "        return examples\n",
        "\n",
        "    def create_lyrics_examples(self, row: pd.Series) -> List[Dict]:\n",
        "        \"\"\"Generate lyrics query examples\"\"\"\n",
        "        examples = []\n",
        "\n",
        "        question = f\"What are the lyrics of '{row['Title']}'?\"\n",
        "        answer = f\"Here are the lyrics of '{row['Title']}':\\n\\n{row['Lyrics']}\"\n",
        "        examples.append({\"question\": question, \"answer\": answer})\n",
        "\n",
        "        question_si = f\"'{row['Title']}' à¶œà·“à¶­à¶ºà·š à¶´à¶¯ à¶»à¶ à¶±à¶º à¶¯à·™à¶±à·Šà¶±\"\n",
        "        examples.append({\"question\": question_si, \"answer\": answer})\n",
        "\n",
        "        return examples\n",
        "\n",
        "    def create_metaphor_examples(self, row: pd.Series) -> List[Dict]:\n",
        "        \"\"\"Generate metaphor explanation examples\"\"\"\n",
        "        if pd.isna(row['Metaphor']) or not row['Metaphor'].strip():\n",
        "            return []\n",
        "\n",
        "        examples = []\n",
        "\n",
        "        question = f\"Explain the metaphor '{row['Metaphor']}' from {row['Title']}\"\n",
        "        answer = (\n",
        "            f\"In the song '{row['Title']}', the metaphor '{row['Metaphor']}' \"\n",
        "            f\"uses {row['Source Domain']} to represent {row['Target Domain']}. \"\n",
        "            f\"{row['Meaning']}\"\n",
        "        )\n",
        "        examples.append({\"question\": question, \"answer\": answer})\n",
        "\n",
        "        question2 = f\"What does '{row['Metaphor']}' mean in the song {row['Title']}?\"\n",
        "        examples.append({\"question\": question2, \"answer\": answer})\n",
        "\n",
        "        question_si = f\"'{row['Title']}' à¶œà·“à¶­à¶ºà·š '{row['Metaphor']}' à¶ºà¶± à¶»à·–à¶´à¶šà¶º à¶´à·à·„à·à¶¯à·’à¶½à·’ à¶šà¶»à¶±à·Šà¶±\"\n",
        "        examples.append({\"question\": question_si, \"answer\": answer})\n",
        "\n",
        "        return examples\n",
        "\n",
        "    def create_release_year_examples(self, row: pd.Series) -> List[Dict]:\n",
        "        \"\"\"Generate release year examples\"\"\"\n",
        "        examples = []\n",
        "\n",
        "        question = f\"When was '{row['Title']}' released?\"\n",
        "        answer = f\"'{row['Title']}' was released in {row['Released Year']}.\"\n",
        "        examples.append({\"question\": question, \"answer\": answer})\n",
        "\n",
        "        question_si = f\"'{row['Title']}' à¶œà·“à¶­à¶º à¶±à·’à¶šà·”à¶­à·Š à·€à·–à¶ºà·š à¶šà·€à¶¯à·à¶¯?\"\n",
        "        examples.append({\"question\": question_si, \"answer\": answer})\n",
        "\n",
        "        return examples\n",
        "\n",
        "    def create_album_examples(self, row: pd.Series) -> List[Dict]:\n",
        "        \"\"\"Generate album query examples\"\"\"\n",
        "        examples = []\n",
        "\n",
        "        question = f\"Which album is '{row['Title']}' from?\"\n",
        "        answer = f\"'{row['Title']}' is from the album '{row['Album']}'.\"\n",
        "        examples.append({\"question\": question, \"answer\": answer})\n",
        "\n",
        "        question_si = f\"'{row['Title']}' à¶œà·“à¶­à¶º à¶šà·”à¶¸à¶± à¶‡à¶½à·Šà¶¶à¶¸à¶ºà·š à¶­à·’à¶¶à·šà¶¯?\"\n",
        "        examples.append({\"question\": question_si, \"answer\": answer})\n",
        "\n",
        "        return examples\n",
        "\n",
        "    def create_combined_examples(self, row: pd.Series) -> List[Dict]:\n",
        "        \"\"\"Generate combined information examples\"\"\"\n",
        "        examples = []\n",
        "\n",
        "        # Singer and lyricist\n",
        "        question = f\"Who sang and wrote '{row['Title']}'?\"\n",
        "        answer = f\"'{row['Title']}' was sung by {row['Singer(s)']} and the lyrics were written by {row['Lyricist']}.\"\n",
        "        examples.append({\"question\": question, \"answer\": answer})\n",
        "\n",
        "        # Full details\n",
        "        question = f\"Give me complete details about '{row['Title']}'\"\n",
        "        answer = (\n",
        "            f\"'{row['Title']}' is a Sinhala song with the following details:\\n\"\n",
        "            f\"- Singer(s): {row['Singer(s)']}\\n\"\n",
        "            f\"- Lyricist: {row['Lyricist']}\\n\"\n",
        "            f\"- Music Director: {row['Musician']}\\n\"\n",
        "            f\"- Album: {row['Album']}\\n\"\n",
        "            f\"- Released Year: {row['Released Year']}\"\n",
        "        )\n",
        "        examples.append({\"question\": question, \"answer\": answer})\n",
        "\n",
        "        return examples\n",
        "\n",
        "    def create_artist_portfolio_examples(self) -> List[Dict]:\n",
        "        \"\"\"Generate artist portfolio examples\"\"\"\n",
        "        examples = []\n",
        "\n",
        "        # Group by singer\n",
        "        singer_groups = self.df.groupby('Singer(s)')\n",
        "        for singer, group in singer_groups:\n",
        "            if len(group) >= 2:\n",
        "                song_titles = group['Title'].tolist()[:5]\n",
        "\n",
        "                question = f\"Which songs did {singer} sing?\"\n",
        "                answer = f\"{singer} sang these songs: {', '.join(song_titles)}.\"\n",
        "                examples.append({\"question\": question, \"answer\": answer})\n",
        "\n",
        "                question2 = f\"List songs by {singer}\"\n",
        "                answer2 = f\"Here are songs by {singer}:\\n\" + \"\\n\".join([f\"- {title}\" for title in song_titles])\n",
        "                examples.append({\"question\": question2, \"answer\": answer2})\n",
        "\n",
        "        # Group by lyricist\n",
        "        lyricist_groups = self.df.groupby('Lyricist')\n",
        "        for lyricist, group in lyricist_groups:\n",
        "            if pd.notna(lyricist) and len(group) >= 2:\n",
        "                song_titles = group['Title'].tolist()[:5]\n",
        "\n",
        "                question = f\"Which songs did {lyricist} write?\"\n",
        "                answer = f\"{lyricist} wrote lyrics for: {', '.join(song_titles)}.\"\n",
        "                examples.append({\"question\": question, \"answer\": answer})\n",
        "\n",
        "        return examples\n",
        "\n",
        "    def prepare_all_examples(self) -> List[Dict]:\n",
        "        \"\"\"Generate all training examples\"\"\"\n",
        "        print(\"Generating training examples for Unsloth...\")\n",
        "\n",
        "        all_qa_pairs = []\n",
        "\n",
        "        for idx, row in self.df.iterrows():\n",
        "            if idx % 10 == 0:\n",
        "                print(f\"Processing row {idx}/{len(self.df)}\")\n",
        "\n",
        "            all_qa_pairs.extend(self.create_song_info_examples(row))\n",
        "            all_qa_pairs.extend(self.create_singer_examples(row))\n",
        "            all_qa_pairs.extend(self.create_lyricist_examples(row))\n",
        "            all_qa_pairs.extend(self.create_musician_examples(row))\n",
        "            all_qa_pairs.extend(self.create_lyrics_examples(row))\n",
        "            all_qa_pairs.extend(self.create_metaphor_examples(row))\n",
        "            all_qa_pairs.extend(self.create_release_year_examples(row))\n",
        "            all_qa_pairs.extend(self.create_album_examples(row))\n",
        "            all_qa_pairs.extend(self.create_combined_examples(row))\n",
        "\n",
        "        all_qa_pairs.extend(self.create_artist_portfolio_examples())\n",
        "\n",
        "        print(f\"\\nTotal Q&A pairs generated: {len(all_qa_pairs)}\")\n",
        "        return all_qa_pairs\n",
        "\n",
        "    def format_for_unsloth(self, qa_pairs: List[Dict], eos_token) -> List[Dict]:\n",
        "        \"\"\"\n",
        "        Format Q&A pairs into the text format expected by Unsloth/SFTTrainer\n",
        "        Similar to your formatting_prompts_func\n",
        "        \"\"\"\n",
        "        formatted_data = []\n",
        "\n",
        "        for qa in qa_pairs:\n",
        "            text = self.prompt_template.format(qa['question'], qa['answer'])\n",
        "            text = text + eos_token\n",
        "            formatted_data.append({\"text\": text})\n",
        "\n",
        "        return formatted_data\n",
        "\n",
        "    def create_hf_dataset(self, eos_token):\n",
        "        \"\"\"\n",
        "        Create HuggingFace Dataset object compatible with Unsloth\n",
        "        \"\"\"\n",
        "        # Generate Q&A pairs\n",
        "        qa_pairs = self.prepare_all_examples()\n",
        "\n",
        "        # Format for Unsloth\n",
        "        formatted_data = self.format_for_unsloth(qa_pairs, eos_token)\n",
        "\n",
        "        # Convert to HuggingFace Dataset\n",
        "        dataset = Dataset.from_list(formatted_data)\n",
        "\n",
        "        print(f\"\\nCreated HuggingFace Dataset with {len(dataset)} examples\")\n",
        "        return dataset\n",
        "\n",
        "    def save_to_json(self, output_file: str = \"sinhala_songs_unsloth.json\"):\n",
        "        \"\"\"Save formatted data to JSON file\"\"\"\n",
        "        qa_pairs = self.prepare_all_examples()\n",
        "        formatted_data = self.format_for_unsloth(qa_pairs)\n",
        "\n",
        "        with open(output_file, 'w', encoding='utf-8') as f:\n",
        "            json.dump(formatted_data, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "        print(f\"Saved {len(formatted_data)} examples to {output_file}\")\n",
        "\n",
        "    def get_statistics(self, qa_pairs: List[Dict] = None):\n",
        "        \"\"\"Print statistics about the dataset\"\"\"\n",
        "        if qa_pairs is None:\n",
        "            qa_pairs = self.prepare_all_examples()\n",
        "\n",
        "        print(\"\\n=== Dataset Statistics ===\")\n",
        "        print(f\"Original songs: {len(self.df)}\")\n",
        "        print(f\"Generated examples: {len(qa_pairs)}\")\n",
        "        print(f\"Average examples per song: {len(qa_pairs) / len(self.df):.1f}\")\n",
        "\n",
        "        # Sample a few examples\n",
        "        print(\"\\n=== Sample Examples ===\")\n",
        "        for i, qa in enumerate(random.sample(qa_pairs, min(3, len(qa_pairs)))):\n",
        "            print(f\"\\nExample {i+1}:\")\n",
        "            print(f\"Q: {qa['question']}\")\n",
        "            print(f\"A: {qa['answer'][:100]}...\")"
      ],
      "metadata": {
        "id": "Lb14tZYr4j5-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor = SinhalaDatasetForUnsloth(df)\n",
        "dataset = preprocessor.create_hf_dataset(eos_token=tokenizer.eos_token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8zhsXoQGYGu",
        "outputId": "5af6967f-7329-46c1-8479-55cd6ef27669"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating training examples for Unsloth...\n",
            "Processing row 0/103\n",
            "Processing row 10/103\n",
            "Processing row 20/103\n",
            "Processing row 30/103\n",
            "Processing row 40/103\n",
            "Processing row 50/103\n",
            "Processing row 60/103\n",
            "Processing row 70/103\n",
            "Processing row 80/103\n",
            "Processing row 90/103\n",
            "Processing row 100/103\n",
            "\n",
            "Total Q&A pairs generated: 2106\n",
            "\n",
            "Created HuggingFace Dataset with 2106 examples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ILz8Dy5MlJH",
        "outputId": "40fe1cfc-ecee-4d09-b880-f6a9010faa23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': \"Below is a question about Sinhala songs. Provide an accurate and helpful answer.\\n        ### Question:\\n        Tell me about the song 'à¶”à¶¶à¶ºà·’ à¶»à¶¸à·Š\\u200dà¶º à·ƒà¶³ à¶šà·’à¶»à¶«'\\n\\n        ### Answer:\\n        à¶”à¶¶à¶ºà·’ à¶»à¶¸à·Š\\u200dà¶º à·ƒà¶³ à¶šà·’à¶»à¶« is a Sinhala song sung by Nanda Malini. The lyrics were written by Sunil Ariyaratne and the music was composed by H. M. Jayawardena. It was released in 1984 as part of the album 'à·ƒà¶­à·Š\\u200dà¶ºà¶ºà·š à¶œà·“à¶­à¶º'.<|eot_id|>\"}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameters config for LoRA\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 16, # rank\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"], # (Wq + Delta W), (Wk + Delta W), etc...\n",
        "    lora_alpha = 16, # a higher alpha value assigned more weight to the LoRA activations\n",
        "    lora_dropout = 0, # supports any but 0 is optimized / dropout nerones in LLM\n",
        "    use_gradient_checkpointing = True, # True or 'unsloth' for vary long context\n",
        "    random_state = 3407,\n",
        "    use_rslora = False,\n",
        "    loftq_config = None\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8G-bGV_MnxJ",
        "outputId": "9c6bd8ab-3aae-4b64-910d-2aafda5b37b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth 2025.12.7 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments, DataCollatorForSeq2Seq\n",
        "from unsloth import is_bfloat16_supported\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    train_dataset = dataset,\n",
        "    dataset_text_field = \"text\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    dataset_num_proc = 2, # no of processors to use for processing the dataset\n",
        "    packing = False,\n",
        "    args = TrainingArguments(\n",
        "        per_device_train_batch_size = 2, # batch size per GPU/TPU core\n",
        "        gradient_accumulation_steps = 4, # gradient accumulation steps\n",
        "        warmup_steps = 5, # few updates with low learing rate before actual training\n",
        "        max_steps = 60,\n",
        "        learning_rate = 2e-4, # learning rate\n",
        "        fp16 = not is_bfloat16_supported(), # whether to use bfloat16 or float32\n",
        "        bf16 = is_bfloat16_supported(), # whether to use bfloat16 or float32\n",
        "        logging_steps = 1, # logging steps\n",
        "        optim = \"adamw_8bit\", # optimizer\n",
        "        weight_decay = 0.01,\n",
        "        lr_scheduler_type = \"linear\",\n",
        "        seed = 3407,\n",
        "        output_dir = \"outputs\", # output directory\n",
        "        report_to = \"none\", # no logging\n",
        "    ),\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "34cb9a43b2b54083acc78a3fb3b80386",
            "e6059945fdc3478f8ae83fc423706ebf",
            "b6b14066efdd4db88eb95871ec57b6cf",
            "48fe21f9340549f4a530f50079fd1e2c",
            "c0b54973752446d0ba79a9b51b3fff64",
            "c637551a165b44338e78dc0d250198a2",
            "b40706a44c0345a8a0443ee4ee0280a3",
            "3a8c2b68546240f583313449183c9e7b",
            "44cbc270a57e45f59d2787af8515a75c",
            "54b0686bd81d4f4cbc60c5047b355330",
            "d0ccac08e8164746972cee35eee8c4f6"
          ]
        },
        "id": "YL4ZmKEhM_ZC",
        "outputId": "459bd84c-6a9f-4c52-bb61-77b6b60fff01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Unsloth: Tokenizing [\"text\"] (num_proc=6):   0%|          | 0/2106 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "34cb9a43b2b54083acc78a3fb3b80386"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_stats = trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uMfO-PmZNR2R",
        "outputId": "58dea7bb-7e2f-43c9-9f98-392e0771fb3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The model is already on multiple devices. Skipping the move to device specified in `args`.\n",
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 2,106 | Num Epochs = 1 | Total steps = 60\n",
            "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n",
            " \"-____-\"     Trainable parameters = 41,943,040 of 8,072,204,288 (0.52% trained)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Will smartly offload gradients to save VRAM!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [60/60 08:44, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.267400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.509700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.271200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.150000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.030600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.129300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.048500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.070200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.941200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.764900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.968700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.999800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.755200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.538900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.667000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.651200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.662000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.695000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.453400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.793200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.388000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.481100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.660600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.466400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.419200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.443600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.588800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.395900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.607300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.581600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.415200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.497400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.802100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>0.480300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.604200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.350900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.568400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.695600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.731700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.555600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>0.458600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>0.440000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>0.672400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>0.446900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.558100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>0.382100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>0.423100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.507100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>0.249600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.360400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>0.416400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>0.413500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53</td>\n",
              "      <td>0.505300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>0.378600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>0.616800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>0.430700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>0.498900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>0.537000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59</td>\n",
              "      <td>0.482500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.457500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth.chat_templates import get_chat_template\n",
        "\n",
        "sys_prompt = \"\"\"You are a reflective assistant engaging in thorough, iterative reasoning, mimicking human stream of consciousness thinking. Your approach emphasizes the exploration, self doubt, and continuous refinement before coming up with an answer.\n",
        "<problem>\n",
        "{}\n",
        "</problem>\n",
        "\"\"\"\n",
        "\n",
        "message = sys_prompt.format(\"name few songs that sing by Victor Rathnayake'?\")\n",
        "tokenizer = get_chat_template(\n",
        "    tokenizer,\n",
        "    chat_template = \"llama-3.1\",\n",
        ")\n",
        "\n",
        "FastLanguageModel.for_inference(model) # enable native 2x faster inference\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": message}\n",
        "]\n",
        "\n",
        "inputs = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    tokenizer = True,\n",
        "    add_generation_prompt = True, # must add for generation\n",
        "    return_tensors = \"pt\",\n",
        ").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(input_ids = inputs, max_new_tokens = 1024, use_cache = True, temperature = 1.5, min_p = 0.1)\n",
        "response = tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "id": "bBYURI-UNfIN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "VXPfQo8zPa5e",
        "outputId": "77901ffc-901e-4576-d0b9-dfeb030235d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 July 2024\\n\\n<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nYou are a reflective assistant engaging in thorough, iterative reasoning, mimicking human stream of consciousness thinking. Your approach emphasizes the exploration, self doubt, and continuous refinement before coming up with an answer.\\n<problem>\\nname few songs that sing by Victor Rathnayake'?\\n</problem>\\n<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nSongs sung by Victor Rathnayake... Let me think for a moment...\\n\\nI remember Victor Rathnayake sang 'à¶šà¶½à· à¶­à·”à·€à¶»à¶šà·’'... or is that incorrect? I need more context...\\n\\nAh yes, I'm pretty sure Victor Rathnayake sang 'à¶šà¶½à· à¶­à·”à·€à¶»à¶šà·’'...\\n\\nAnother one that comes to mind is 'à¶»à¶§ à·€à·à·€à·™à¶±à· à¶šà·’à¶ºà¶½à· à¶šà¶­à¶»à·’...'...\\n\\nThat's not the one that comes to my mind, let me check other songs...\\n\\nAh 'à¶¯à·”à¶» à¶±à·’à·€à· à·„à·™à·…à·™à¶±à· à¶¶à·à¶¸à¶»à¶ºà·™à¶šà·’'<|eot_id|>\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    }
  ]
}